{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f33b492-d74f-41f1-a7e5-d10dc1c41edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models.segmentation import deeplabv3_resnet50\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA Device: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43c5e6d4-f059-465b-99d8-3214f34798c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    \"\"\"Configuration parameters for training\"\"\"\n",
    "    # Dataset paths (adjust for your environment)\n",
    "    BASE_DIR = \"/kaggle/input/cvcclinicdb/PNG\"  # Change this to your path\n",
    "    IMAGE_DIR = os.path.join(BASE_DIR, \"Original\")\n",
    "    MASK_DIR = os.path.join(BASE_DIR, \"Ground Truth\")\n",
    "    \n",
    "    # Training hyperparameters\n",
    "    IMG_SIZE = 512\n",
    "    BATCH_SIZE = 8\n",
    "    LEARNING_RATE = 1e-4\n",
    "    NUM_EPOCHS = 50\n",
    "    DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Loss function weights\n",
    "    DICE_BCE_ALPHA = 0.5  # Weight for Dice vs BCE loss\n",
    "    \n",
    "    # Random seed for reproducibility\n",
    "    SEED = 42\n",
    "\n",
    "config = Config()\n",
    "torch.manual_seed(config.SEED)\n",
    "print(f\"Using device: {config.DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da68048-b55b-4fe2-8dab-f94c41490b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVCClinicDBDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for CVC-ClinicDB polyp segmentation.\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of paths to input images\n",
    "        mask_paths (list): List of paths to segmentation masks\n",
    "        transform: Transformations to apply to images\n",
    "        mask_transform: Transformations to apply to masks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, mask_paths, transform=None, mask_transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and mask\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        \n",
    "        # Binarize mask: convert from [0, 255] to [0, 1]\n",
    "        mask = (mask > 0).float()\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88ae9c70-951f-4644-b845-a444cf81bcb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CVCClinicDBDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Custom Dataset for CVC-ClinicDB polyp segmentation.\n",
    "    \n",
    "    Args:\n",
    "        image_paths (list): List of paths to input images\n",
    "        mask_paths (list): List of paths to segmentation masks\n",
    "        transform: Transformations to apply to images\n",
    "        mask_transform: Transformations to apply to masks\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, mask_paths, transform=None, mask_transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.mask_paths = mask_paths\n",
    "        self.transform = transform\n",
    "        self.mask_transform = mask_transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load image and mask\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        mask = Image.open(self.mask_paths[idx]).convert('L')\n",
    "        \n",
    "        # Apply transformations\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.mask_transform:\n",
    "            mask = self.mask_transform(mask)\n",
    "        \n",
    "        # Binarize mask: convert from [0, 255] to [0, 1]\n",
    "        mask = (mask > 0).float()\n",
    "        \n",
    "        return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494b44fc-0727-42b9-8704-61096b50a84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_iou(pred, target, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Calculate Intersection over Union (IoU/Jaccard Index).\n",
    "    \n",
    "    Args:\n",
    "        pred: Model predictions (logits)\n",
    "        target: Ground truth masks\n",
    "        threshold: Threshold for binary prediction\n",
    "    \n",
    "    Returns:\n",
    "        IoU score\n",
    "    \"\"\"\n",
    "    pred = (torch.sigmoid(pred) > threshold).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    union = pred.sum() + target.sum() - intersection\n",
    "    iou = (intersection + 1e-5) / (union + 1e-5)\n",
    "    return iou.item()\n",
    "\n",
    "\n",
    "def calculate_dice(pred, target, threshold=0.5):\n",
    "    pred = (torch.sigmoid(pred) > threshold).float()\n",
    "    intersection = (pred * target).sum()\n",
    "    dice = (2. * intersection + 1e-5) / (pred.sum() + target.sum() + 1e-5)\n",
    "    return dice.item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c936539-4335-4206-9b9c-bb22d84531f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    Train the model for one epoch.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (average_loss, average_iou, average_dice)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_dice = 0.0\n",
    "    \n",
    "    progress_bar = tqdm(dataloader, desc=\"Training\")\n",
    "    for images, masks in progress_bar:\n",
    "        images = images.to(device)\n",
    "        masks = masks.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)['out']\n",
    "        loss = criterion(outputs, masks)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Calculate metrics\n",
    "        batch_iou = calculate_iou(outputs, masks)\n",
    "        batch_dice = calculate_dice(outputs, masks)\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        running_iou += batch_iou\n",
    "        running_dice += batch_dice\n",
    "        \n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({\n",
    "            'loss': f'{loss.item():.4f}',\n",
    "            'dice': f'{batch_dice:.4f}'\n",
    "        })\n",
    "    \n",
    "    # Calculate epoch averages\n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    epoch_dice = running_dice / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_iou, epoch_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0ca0a3-d58c-4de2-9f1c-7b54bf84479f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, dataloader, criterion, device):\n",
    "    \"\"\"\n",
    "    Validate the model.\n",
    "    \n",
    "    Returns:\n",
    "        Tuple of (average_loss, average_iou, average_dice)\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    running_iou = 0.0\n",
    "    running_dice = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        progress_bar = tqdm(dataloader, desc=\"Validation\")\n",
    "        for images, masks in progress_bar:\n",
    "            images = images.to(device)\n",
    "            masks = masks.to(device)\n",
    "            \n",
    "            outputs = model(images)['out']\n",
    "            loss = criterion(outputs, masks)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            running_iou += calculate_iou(outputs, masks)\n",
    "            running_dice += calculate_dice(outputs, masks)\n",
    "            \n",
    "            progress_bar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_iou = running_iou / len(dataloader)\n",
    "    epoch_dice = running_dice / len(dataloader)\n",
    "    \n",
    "    return epoch_loss, epoch_iou, epoch_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ae60314-f0b5-4888-bab7-540b6797e04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_predictions(model, dataset, device, num_samples=5, save_path='predictions.png'):\n",
    "    \"\"\"Generate and save visualization of model predictions.\"\"\"\n",
    "    model.eval()\n",
    "    fig, axes = plt.subplots(num_samples, 3, figsize=(15, 5*num_samples))\n",
    "    \n",
    "    # Handle single sample case\n",
    "    if num_samples == 1:\n",
    "        axes = axes.reshape(1, -1)\n",
    "    \n",
    "    for i in range(num_samples):\n",
    "        image, mask = dataset[i]\n",
    "        \n",
    "        # Generate prediction\n",
    "        with torch.no_grad():\n",
    "            image_input = image.unsqueeze(0).to(device)\n",
    "            output = model(image_input)['out']\n",
    "            pred = torch.sigmoid(output).cpu().squeeze().numpy()\n",
    "        \n",
    "        # Denormalize image for visualization\n",
    "        image_np = image.cpu().numpy().transpose(1, 2, 0)\n",
    "        mean = np.array([0.485, 0.456, 0.406])\n",
    "        std = np.array([0.229, 0.224, 0.225])\n",
    "        image_np = std * image_np + mean\n",
    "        image_np = np.clip(image_np, 0, 1)\n",
    "        \n",
    "        # Plot original image, ground truth, and prediction\n",
    "        axes[i, 0].imshow(image_np)\n",
    "        axes[i, 0].set_title('Original Image', fontsize=12, fontweight='bold')\n",
    "        axes[i, 0].axis('off')\n",
    "        \n",
    "        axes[i, 1].imshow(mask.squeeze(), cmap='gray')\n",
    "        axes[i, 1].set_title('Ground Truth', fontsize=12, fontweight='bold')\n",
    "        axes[i, 1].axis('off')\n",
    "        \n",
    "        axes[i, 2].imshow(pred, cmap='gray')\n",
    "        axes[i, 2].set_title('Prediction', fontsize=12, fontweight='bold')\n",
    "        axes[i, 2].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Predictions saved to {save_path}\")\n",
    "\n",
    "\n",
    "def plot_training_curves(train_losses, val_losses, train_dices, val_dices, save_path='training_curves.png'):\n",
    "    \"\"\"Plot and save training curves.\"\"\"\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "    \n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Loss curve\n",
    "    axes[0].plot(epochs, train_losses, 'b-', label='Train Loss', linewidth=2, marker='o', markersize=4)\n",
    "    axes[0].plot(epochs, val_losses, 'r-', label='Val Loss', linewidth=2, marker='s', markersize=4)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_ylabel('Loss', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_title('Loss Curve', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Dice score curve\n",
    "    axes[1].plot(epochs, train_dices, 'b-', label='Train Dice', linewidth=2, marker='o', markersize=4)\n",
    "    axes[1].plot(epochs, val_dices, 'r-', label='Val Dice', linewidth=2, marker='s', markersize=4)\n",
    "    axes[1].set_xlabel('Epoch', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('Dice Score', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_title('Dice Score Curve', fontsize=14, fontweight='bold')\n",
    "    axes[1].legend(fontsize=11)\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    print(f\"Training curves saved to {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0119a844-8356-4287-8a8e-ecaec41a64a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Loading dataset...\")\n",
    "print(f\"Image directory: {config.IMAGE_DIR}\")\n",
    "print(f\"Mask directory: {config.MASK_DIR}\")\n",
    "\n",
    "# Get image and mask paths\n",
    "image_files = sorted(glob.glob(os.path.join(config.IMAGE_DIR, \"*.png\")))\n",
    "mask_files = sorted(glob.glob(os.path.join(config.MASK_DIR, \"*.png\")))\n",
    "\n",
    "# Verify dataset\n",
    "assert len(image_files) == len(mask_files), \\\n",
    "    f\"Mismatch: {len(image_files)} images, {len(mask_files)} masks\"\n",
    "assert len(image_files) > 0, \"No images found! Check your dataset path.\"\n",
    "\n",
    "print(f\"\\nâœ“ Found {len(image_files)} images and {len(mask_files)} masks\")\n",
    "\n",
    "# Display sample filenames\n",
    "print(\"\\nSample files:\")\n",
    "for i in range(min(3, len(image_files))):\n",
    "    print(f\"  Image: {os.path.basename(image_files[i])}\")\n",
    "    print(f\"  Mask:  {os.path.basename(mask_files[i])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2ec69b-9d0f-4af7-908a-d5fc032fbcbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset: 80% train, 10% val, 10% test\n",
    "train_imgs, temp_imgs, train_masks, temp_masks = train_test_split(\n",
    "    image_files, mask_files, test_size=0.2, random_state=config.SEED\n",
    ")\n",
    "val_imgs, test_imgs, val_masks, test_masks = train_test_split(\n",
    "    temp_imgs, temp_masks, test_size=0.5, random_state=config.SEED\n",
    ")\n",
    "\n",
    "print(f\"\\nDataset split:\")\n",
    "print(f\"  Training:   {len(train_imgs)} samples ({len(train_imgs)/len(image_files)*100:.1f}%)\")\n",
    "print(f\"  Validation: {len(val_imgs)} samples ({len(val_imgs)/len(image_files)*100:.1f}%)\")\n",
    "print(f\"  Test:       {len(test_imgs)} samples ({len(test_imgs)/len(image_files)*100:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9846d6-8afd-464d-9a43-97d549330877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training transformations (with data augmentation)\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomVerticalFlip(p=0.5),\n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Validation/Test transformations (no augmentation)\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Mask transformations (same for train/val/test)\n",
    "mask_transform = transforms.Compose([\n",
    "    transforms.Resize((config.IMG_SIZE, config.IMG_SIZE)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "print(\"âœ“ Data transformations configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43283c84-b9fb-47c5-9773-1e69626b0770",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = CVCClinicDBDataset(train_imgs, train_masks, train_transform, mask_transform)\n",
    "val_dataset = CVCClinicDBDataset(val_imgs, val_masks, val_transform, mask_transform)\n",
    "test_dataset = CVCClinicDBDataset(test_imgs, test_masks, val_transform, mask_transform)\n",
    "\n",
    "# Create dataloaders\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    shuffle=True, \n",
    "    num_workers=2, \n",
    "    pin_memory=True\n",
    ")\n",
    "val_loader = DataLoader(\n",
    "    val_dataset, \n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=2, \n",
    "    pin_memory=True\n",
    ")\n",
    "test_loader = DataLoader(\n",
    "    test_dataset, \n",
    "    batch_size=config.BATCH_SIZE, \n",
    "    shuffle=False, \n",
    "    num_workers=2, \n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(f\"âœ“ DataLoaders created\")\n",
    "print(f\"  Training batches:   {len(train_loader)}\")\n",
    "print(f\"  Validation batches: {len(val_loader)}\")\n",
    "print(f\"  Test batches:       {len(test_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7b2216b-316f-489e-bbdb-f6c93a6c877b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Initializing DeepLabV3 model with ResNet50 backbone...\")\n",
    "\n",
    "# Load pretrained DeepLabV3\n",
    "model = deeplabv3_resnet50(pretrained=True)\n",
    "\n",
    "# Modify classifier for binary segmentation (1 output channel)\n",
    "model.classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "model.aux_classifier[4] = nn.Conv2d(256, 1, kernel_size=1)\n",
    "\n",
    "# Move model to device\n",
    "model = model.to(config.DEVICE)\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f\"âœ“ Model loaded successfully\")\n",
    "print(f\"  Total parameters: {total_params:,}\")\n",
    "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
    "\n",
    "# Loss function\n",
    "criterion = DiceBCELoss(alpha=config.DICE_BCE_ALPHA)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adam(model.parameters(), lr=config.LEARNING_RATE)\n",
    "\n",
    "# Learning rate scheduler\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    optimizer, \n",
    "    mode='min', \n",
    "    patience=5, \n",
    "    factor=0.5, \n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "print(\"âœ“ Loss function, optimizer, and scheduler configured\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4992a82-513a-4ec5-91e0-33dc75b1f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_val_dice = 0.0\n",
    "train_losses, val_losses = [], []\n",
    "train_dices, val_dices = [], []\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(f\"Starting training for {config.NUM_EPOCHS} epochs\")\n",
    "print(f\"{'='*70}\\n\")\n",
    "\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "    print(f\"\\nEpoch {epoch+1}/{config.NUM_EPOCHS}\")\n",
    "    print(\"-\" * 70)\n",
    "    \n",
    "    # Train\n",
    "    train_loss, train_iou, train_dice = train_one_epoch(\n",
    "        model, train_loader, criterion, optimizer, config.DEVICE\n",
    "    )\n",
    "    \n",
    "    # Validate\n",
    "    val_loss, val_iou, val_dice = validate(\n",
    "        model, val_loader, criterion, config.DEVICE\n",
    "    )\n",
    "    \n",
    "    # Update learning rate\n",
    "    scheduler.step(val_loss)\n",
    "    current_lr = optimizer.param_groups[0]['lr']\n",
    "    \n",
    "    # Store metrics\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_dices.append(train_dice)\n",
    "    val_dices.append(val_dice)\n",
    "    \n",
    "    # Print results\n",
    "    print(f\"\\nResults:\")\n",
    "    print(f\"  Train â†’ Loss: {train_loss:.4f} | IoU: {train_iou:.4f} | Dice: {train_dice:.4f}\")\n",
    "    print(f\"  Val   â†’ Loss: {val_loss:.4f} | IoU: {val_iou:.4f} | Dice: {val_dice:.4f}\")\n",
    "    print(f\"  Learning Rate: {current_lr:.6f}\")\n",
    "    \n",
    "    # Save best model\n",
    "    if val_dice > best_val_dice:\n",
    "        best_val_dice = val_dice\n",
    "        torch.save({\n",
    "            'epoch': epoch,\n",
    "            'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'val_dice': val_dice,\n",
    "        }, 'best_deeplabv3_model.pth')\n",
    "        print(f\"  âœ“ New best model saved! Val Dice: {best_val_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ca129-d4a5-44ef-9cce-0ccc102c6068",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nEvaluating best model on test set...\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "# Load best model\n",
    "checkpoint = torch.load('best_deeplabv3_model.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Test\n",
    "test_loss, test_iou, test_dice = validate(model, test_loader, criterion, config.DEVICE)\n",
    "\n",
    "print(f\"\\nðŸ“Š Final Test Results:\")\n",
    "print(f\"  Test Loss: {test_loss:.4f}\")\n",
    "print(f\"  Test IoU:  {test_iou:.4f}\")\n",
    "print(f\"  Test Dice: {test_dice:.4f}\")\n",
    "print(f\"\\n  Best Val Dice: {best_val_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfd9f1e-2469-4ebd-8c73-e72b6ecfbf49",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nGenerating prediction visualizations...\")\n",
    "visualize_predictions(model, test_dataset, config.DEVICE, num_samples=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6a657e2-50eb-4816-8fca-11cd072eac19",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nPlotting training curves...\")\n",
    "plot_training_curves(train_losses, val_losses, train_dices, val_dices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7216b50d-25a9-42be-8364-bf1be1661a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"TRAINING SUMMARY\")\n",
    "print(f\"Dataset: CVC-ClinicDB\")\n",
    "print(f\"Model: DeepLabV3 with ResNet50 backbone\")\n",
    "print(f\"Total Epochs: {config.NUM_EPOCHS}\")\n",
    "print(f\"\\nBest Validation Dice: {best_val_dice:.4f}\")\n",
    "print(f\"Final Test Dice:      {test_dice:.4f}\")\n",
    "print(f\"Final Test IoU:       {test_iou:.4f}\")\n",
    "print(\"=\"*70)\n",
    "print(\"\\nâœ“ All done! Model saved as 'best_deeplabv3_model.pth'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
